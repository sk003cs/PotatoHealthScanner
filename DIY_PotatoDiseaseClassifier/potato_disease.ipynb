{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 files belonging to 3 classes.\n",
      "Found 300 files belonging to 3 classes.\n",
      "Found 300 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define batch size and image size for training\n",
    "batch_size = 32\n",
    "image_size = (224, 224)\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "# Load datasets from directories and shuffle them with a seed for reproducibility\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../PotatoImagesData/Train',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "classes = train_ds.class_names\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../PotatoImagesData/Valid',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../PotatoImagesData/Test',\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "29/29 [==============================] - 38s 1s/step - loss: 1.0968 - accuracy: 0.3944 - val_loss: 1.0850 - val_accuracy: 0.3333\n",
      "Epoch 2/50\n",
      "29/29 [==============================] - 35s 1s/step - loss: 0.9283 - accuracy: 0.5233 - val_loss: 0.8850 - val_accuracy: 0.6100\n",
      "Epoch 3/50\n",
      "29/29 [==============================] - 35s 1s/step - loss: 0.6948 - accuracy: 0.6822 - val_loss: 0.4803 - val_accuracy: 0.7967\n",
      "Epoch 4/50\n",
      "29/29 [==============================] - 38s 1s/step - loss: 0.4685 - accuracy: 0.7822 - val_loss: 0.5480 - val_accuracy: 0.7500\n",
      "Epoch 5/50\n",
      "29/29 [==============================] - 37s 1s/step - loss: 0.4017 - accuracy: 0.8267 - val_loss: 0.4664 - val_accuracy: 0.7900\n",
      "Epoch 6/50\n",
      "29/29 [==============================] - 40s 1s/step - loss: 0.3234 - accuracy: 0.8722 - val_loss: 0.3088 - val_accuracy: 0.8733\n",
      "Epoch 7/50\n",
      "29/29 [==============================] - 39s 1s/step - loss: 0.3012 - accuracy: 0.8944 - val_loss: 0.4376 - val_accuracy: 0.8033\n",
      "Epoch 8/50\n",
      "29/29 [==============================] - 39s 1s/step - loss: 0.4044 - accuracy: 0.8189 - val_loss: 0.3008 - val_accuracy: 0.8667\n",
      "Epoch 9/50\n",
      "29/29 [==============================] - 35s 1s/step - loss: 0.3069 - accuracy: 0.8767 - val_loss: 0.3000 - val_accuracy: 0.8700\n",
      "Epoch 10/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.2764 - accuracy: 0.8900 - val_loss: 0.2665 - val_accuracy: 0.8700\n",
      "Epoch 11/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.2444 - accuracy: 0.9033 - val_loss: 0.2045 - val_accuracy: 0.9300\n",
      "Epoch 12/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.2673 - accuracy: 0.8989 - val_loss: 0.2765 - val_accuracy: 0.8933\n",
      "Epoch 13/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.2393 - accuracy: 0.9144 - val_loss: 0.1583 - val_accuracy: 0.9433\n",
      "Epoch 14/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.2012 - accuracy: 0.9289 - val_loss: 0.1718 - val_accuracy: 0.9267\n",
      "Epoch 15/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.1550 - accuracy: 0.9456 - val_loss: 0.1273 - val_accuracy: 0.9433\n",
      "Epoch 16/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.1743 - accuracy: 0.9333 - val_loss: 0.2589 - val_accuracy: 0.8933\n",
      "Epoch 17/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.1669 - accuracy: 0.9344 - val_loss: 0.1231 - val_accuracy: 0.9467\n",
      "Epoch 18/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.1371 - accuracy: 0.9478 - val_loss: 0.3448 - val_accuracy: 0.8567\n",
      "Epoch 19/50\n",
      "29/29 [==============================] - 33s 1s/step - loss: 0.1358 - accuracy: 0.9467 - val_loss: 0.2262 - val_accuracy: 0.9167\n",
      "Epoch 20/50\n",
      "29/29 [==============================] - 34s 1s/step - loss: 0.1468 - accuracy: 0.9533 - val_loss: 0.1946 - val_accuracy: 0.9267\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.1140 - accuracy: 0.9633\n",
      "Test Loss: 0.1140035018324852, Test Accuracy: 0.9633333086967468\n"
     ]
    }
   ],
   "source": [
    "# Image preprocessing - rescaling pixel values\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1.0/255), #normalise 0-255 to 0-1   \n",
    "])\n",
    "\n",
    "# Data augmentation - applying random transformations for robustness - Horizontal flip, Vertical flip, Rotate, Contrast, Zoom\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
    "])\n",
    "\n",
    "# Model definition - a series of convolutional and pooling layers\n",
    "model = tf.keras.Sequential([\n",
    "    resize_and_rescale,\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = input_shape),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, kernel_size = (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(len(classes), activation = 'softmax'), # softmax -> normalize probability of classes \n",
    "])\n",
    "\n",
    "# Model compilation with Adam optimizer and loss function\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Model training with validation data and early stopping\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "# Model evaluation on test data\n",
    "evaluation_results = model.evaluate(test_ds)\n",
    "print(f\"Test Loss: {evaluation_results[0]}, Test Accuracy: {evaluation_results[1]}\")\n",
    "\n",
    "# Saving the trained model\n",
    "model.save('potato_disease.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('potato_disease.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "Potato___Early_blight\n",
      "Potato___Late_blight\n",
      "Potato___healthy\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert image file to array\n",
    "def get_img_array(image_path, target_size=image_size):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=target_size)\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "# Making predictions using the model\n",
    "predictions = model.predict(np.array([\n",
    "    get_img_array(\"../PotatoImagesData/Train/Potato___Early_blight/bb07a1b7-b9ad-4016-a013-9ff0e4636d4a___RS_Early.B 7156.JPG\"),\n",
    "    get_img_array(\"../PotatoImagesData/Train/Potato___Late_blight/fd35fb86-6558-40f2-b8ac-6922e2107af5___RS_LB 4095.JPG\"),\n",
    "    get_img_array(\"../PotatoImagesData/Train/Potato___healthy/Potato_healthy-103-_0_3577.jpg\"),\n",
    "]))\n",
    "\n",
    "# Printing the predicted classes\n",
    "for i in predictions:\n",
    "    print(classes[np.argmax(i)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mojo-CiaEp4gG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
